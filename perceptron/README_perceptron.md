
# ğŸ§  PerceptrÃ³n: Fundamentos, MatemÃ¡tica y VisualizaciÃ³n

Este proyecto explica desde cero el concepto del **PerceptrÃ³n**, uno de los modelos fundamentales en el campo de la inteligencia artificial y aprendizaje automÃ¡tico. EstÃ¡ inspirado en el libro _"Neural Networks and Deep Learning"_ de Charu C. Aggarwal, y pensado para estudiantes que deseen **entender, programar y visualizar** el algoritmo de manera didÃ¡ctica.

---

## ğŸ” Â¿QuÃ© es un PerceptrÃ³n?

El **perceptrÃ³n** es el modelo mÃ¡s simple de una neurona artificial. Fue propuesto por Frank Rosenblatt en 1958 y sirve como clasificador binario lineal. Dado un conjunto de entradas numÃ©ricas (features), el perceptrÃ³n intenta aprender un **hiperplano de separaciÃ³n** que divida correctamente dos clases distintas.

---

## ğŸ“ EcuaciÃ³n del modelo

El perceptrÃ³n toma una entrada `x` (un vector de caracterÃ­sticas) y predice una etiqueta mediante la funciÃ³n de activaciÃ³n **signo** (`sign`):

```math
\hat{y} = \text{sign}( \mathbf{w}^\top \mathbf{x} + b )
```

ğŸ“– **Lectura matemÃ¡tica precisa**:  
â€œLa y sombrero es igual al signo de el producto punto entre el vector de pesos w transpuesto y el vector de caracterÃ­sticas x, mÃ¡s el sesgo b.â€

---

## ğŸ¯ Objetivo de entrenamiento

El objetivo del perceptrÃ³n es encontrar los pesos `w` y el sesgo `b` que clasifiquen correctamente todos los ejemplos de entrenamiento linealmente separables.  
Se usa una regla de aprendizaje muy simple basada en errores:

- Si una predicciÃ³n es incorrecta, se **actualizan** los pesos y el sesgo:
  
```math
\mathbf{w} \leftarrow \mathbf{w} + \eta \cdot y_i \cdot \mathbf{x}_i
```
```math
b \leftarrow b + \eta \cdot y_i
```

ğŸ“– **Lectura**:  
â€œw se actualiza como w mÃ¡s el producto de eta por y sub i por x sub i.  
b se actualiza como b mÃ¡s eta por y sub i.â€

---

## âš™ï¸ ImplementaciÃ³n en Python

El cÃ³digo incluido en este repositorio:

- Genera un conjunto de datos 2D simple con dos clases linealmente separables.
- Implementa el algoritmo de entrenamiento del perceptrÃ³n desde cero.
- Visualiza el conjunto de datos, la frontera de decisiÃ³n y el comportamiento del modelo.

ğŸ“ Estructura de archivos:

```
ğŸ“¦ perceptron
 â”£ ğŸ“œ perceptron.py        # ImplementaciÃ³n principal
 â”£ ğŸ“œ README.md            # Este archivo
 â”— ğŸ“Š grÃ¡fica.png          # VisualizaciÃ³n del resultado
```

---

## ğŸ“Š VisualizaciÃ³n

La visualizaciÃ³n muestra:

- Puntos de datos con colores por clase.
- Frontera de decisiÃ³n aprendida.
- Cambios de la lÃ­nea separadora a lo largo de las Ã©pocas (si se activa animaciÃ³n).

Este enfoque visual ayuda a **entender intuitivamente** cÃ³mo el perceptrÃ³n ajusta los pesos para encontrar una soluciÃ³n.

---

## âš ï¸ Limitaciones del PerceptrÃ³n

- Solo funciona correctamente si los datos son **linealmente separables**.
- No aprende probabilidades, solo clases (+1 o -1).
- No converge si los datos son ruidosos o no separables linealmente.

---

## ğŸ§  Â¿QuÃ© aprendÃ©s con este proyecto?

- Fundamentos de redes neuronales.
- ImplementaciÃ³n desde cero de un modelo de IA.
- CÃ³mo se entrena una red con errores.
- El rol de los vectores de caracterÃ­sticas y pesos.
- VisualizaciÃ³n de modelos en 2D.

---

## ğŸ—‚ï¸ Requisitos

- Python 3.7+
- numpy
- matplotlib

InstalaciÃ³n:

```bash
pip install numpy matplotlib
```

---

## ğŸ¥ Video explicativo

ğŸ‘‰ Pronto disponible en YouTube  
ğŸ“ [Enlace al repositorio y ejemplo visual]()

---

## ğŸ“š Referencias

- Charu C. Aggarwal â€” *Neural Networks and Deep Learning*
- F. Rosenblatt (1958) â€” *The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain*
- [Wikipedia: Perceptron](https://es.wikipedia.org/wiki/Perceptr%C3%B3n)

---

## ğŸ¤– Autor

Tony Gael â€” Estudiante de Licenciatura en Inteligencia Artificial y RobÃ³tica  
Contribuciones educativas con fines didÃ¡cticos.
